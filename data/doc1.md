Title: Data ingestion basics

Data ingestion is the process of collecting data from different sources and moving it into a system where it can be stored and analyzed.
Common ingestion patterns are batch ingestion (scheduled loads) and streaming ingestion (continuous events).
Typical sources include APIs, databases, logs, and files. A good ingestion pipeline validates data, handles errors, and tracks metadata.
